{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload covid data to Socrata\n",
    "\n",
    "References:\n",
    "\n",
    "* [socrata-py package](https://github.com/socrata/socrata-py)\n",
    "* [sodapy package](https://pypi.org/project/sodapy/)\n",
    "* [Socrata Data Management experience](https://support.socrata.com/hc/en-us/articles/115016067067-Using-the-Socrata-Data-Management-Experience)\n",
    "* [some examples](https://github.com/xmunoz/sodapy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sodapy\n",
    "\n",
    "import neighborhood_utils\n",
    "import utils\n",
    "import credentials\n",
    "\n",
    "BUCKET_NAME = \"public-health-dashboard\"\n",
    "S3_FILE_PATH = f\"s3://{BUCKET_NAME}/jhu_covid19/\"\n",
    " \n",
    "client = sodapy.Socrata(\"data.lacity.org\", \n",
    "                        app_token = None,\n",
    "                        username = credentials.SOCRATA_USERNAME,\n",
    "                        password = credentials.SOCRATA_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_processing(csv_file):\n",
    "    if csv_file==\"us-county-time-series.csv\":\n",
    "        parquet_file = csv_file.replace('.csv', '.parquet')\n",
    "        df = pd.read_parquet(f\"{S3_FILE_PATH}{parquet_file}\")\n",
    "        df = df.assign(\n",
    "            date = pd.to_datetime(df.date).dt.date,\n",
    "        )\n",
    "        \n",
    "        \n",
    "    elif csv_file==\"la-county-neighborhood-time-series.csv\":\n",
    "        df = neighborhood_utils.clean_data()\n",
    "\n",
    "        keep_cols = [\n",
    "            \"aggregate_region\", \"population\", \"date\", \"date2\", \n",
    "            \"cases\", \"deaths\", \"new_cases\", \"new_deaths\",\n",
    "            \"cases_per100k\", \"deaths_per100k\",\n",
    "            \"cases_avg7\", \"deaths_avg7\",\n",
    "            \"new_cases_avg7\", \"new_deaths_avg7\",\n",
    "            \"cases_per100k_avg7\", \"deaths_per100k_avg7\",\n",
    "        ]\n",
    "\n",
    "        df = df[keep_cols]\n",
    "        \n",
    "    elif csv_file==\"vaccinations-by-county.csv\":\n",
    "        df = pd.read_csv(utils.COUNTY_VACCINE_URL)\n",
    "    \n",
    "        population = pd.read_parquet(f\"{S3_FILE_PATH}ca_county_pop_crosswalk.parquet\")    \n",
    "    \n",
    "        df = pd.merge(df, population, \n",
    "                      on = \"county\",\n",
    "                      how = \"inner\", validate = \"m:1\")\n",
    "    \n",
    "        df = df.assign(\n",
    "            date = pd.to_datetime(df.administered_date),\n",
    "        )\n",
    "        \n",
    "    elif csv_file==\"vaccinations-by-demographics-county.csv\":\n",
    "        df = pd.read_csv(utils.COUNTY_DEMOGRAPHICS_URL)\n",
    "        df = df.assign(\n",
    "            date = pd.to_datetime(df.administered_date),\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "def overwrite_socrata_table(csv_file, socrata_dataset_id, NUM_MINUTES=20):    \n",
    "    data = open(f\"{csv_file}\")\n",
    "    \n",
    "    client.timeout = (NUM_MINUTES * 60)\n",
    "    client.replace(socrata_dataset_id, data)\n",
    "    \n",
    "    print(f\"{csv_file} updated\")\n",
    "    os.remove(f\"{csv_file}\")\n",
    "    \n",
    "    \n",
    "def upsert_socrata_rows(csv_file, socrata_dataset_id, NUM_MINUTES=5):\n",
    "    # Grab existing table in Socrata and find where it leaves off\n",
    "    existing_table = client.get(socrata_dataset_id)\n",
    "    existing_table = pd.DataFrame(existing_table)\n",
    "    max_date = pd.to_datetime(existing_table.date.max())\n",
    "    \n",
    "    df = pd.read_csv(f\"{csv_file}\")\n",
    "    df = df.assign(\n",
    "        date = pd.to_datetime(df.date)\n",
    "    )\n",
    "    \n",
    "    # Now, overwrite the local CSV with just the rows we need to upsert\n",
    "    df[df.date > max_date].to_csv(f\"{csv_file}\" , index=False)\n",
    "    \n",
    "    data = open(f\"{csv_file}\")\n",
    "    \n",
    "    client.timeout = (NUM_MINUTES * 60)\n",
    "    client.upsert(socrata_dataset_id, data)\n",
    "\n",
    "    print(f\"{csv_file} updated\")\n",
    "    os.remove(f\"{csv_file}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-county-time-series.csv updated\n",
      "la-county-neighborhood-time-series.csv updated\n",
      "vaccinations-by-county.csv updated\n",
      "vaccinations-by-demographics-county.csv updated\n"
     ]
    }
   ],
   "source": [
    "DATAFRAME_DICT = {\n",
    "    # key: socrata_dataset_id\n",
    "    # value: csv file\n",
    "    \"jsff-uc6b\": \"us-county-time-series.csv\",\n",
    "    \"fvye-93wd\": \"la-county-neighborhood-time-series.csv\",\n",
    "    \"rpp7-mevy\": \"vaccinations-by-county.csv\",\n",
    "    \"iv7a-6rrq\": \"vaccinations-by-demographics-county.csv\"\n",
    "}\n",
    "\n",
    "for socrata_id, filename in DATAFRAME_DICT.items():\n",
    "    # So far, all the datasets need some extra processing to make sure Socrata table schema is correct\n",
    "    if ((\"us-county\" in filename) or \n",
    "        (\"neighborhood\" in filename) or \n",
    "        (\"vaccinations\" in filename)):\n",
    "        df = extra_processing(filename)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{S3_FILE_PATH}{filename}\")\n",
    "    \n",
    "    # Write the full table out as CSV \n",
    "    df.to_csv(f\"{filename}\", index=False)\n",
    "    \n",
    "    #overwrite_socrata_table(filename, socrata_dataset_id = socrata_id)\n",
    "    upsert_socrata_rows(filename, socrata_dataset_id = socrata_id)\n",
    "    \n",
    "    \n",
    "#s3_to_socrata(\"la-county-neighborhood-time-series.csv\", \n",
    "#              socrata_dataset_id = \"wrj6-vjm7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Errors': 0, 'Rows Created': 2, 'Rows Deleted': 0, 'Rows Updated': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "la = pd.read_csv(\"../notebooks/test_data/us-county-time-series.csv\")\n",
    "la = la[la.county==\"Los Angeles\"]\n",
    "la[la.date < \"2021-08-23\"].to_csv(\"../notebooks/test_data/la.csv\", index=False)\n",
    "la.to_csv(\"../notebooks/test_data/la.csv\", index=False)\n",
    "\n",
    "filename = \"../notebooks/test_data/la.csv\"\n",
    "socrata_dataset_id = \"3cst-kzzr\"\n",
    "existing_table = client.get(socrata_dataset_id)\n",
    "existing_table = pd.DataFrame(existing_table)\n",
    "max_date = pd.to_datetime(existing_table.date.max())\n",
    "\n",
    "t2 = pd.read_csv(f\"{filename}\")\n",
    "t2 = t2.assign(\n",
    "    date = pd.to_datetime(t2.date)\n",
    ")\n",
    "\n",
    "t2[t2.date > max_date].to_csv(filename, index=False)\n",
    "data = open(f\"{filename}\")\n",
    "    \n",
    "client.timeout = (5 * 60)\n",
    "client.upsert(socrata_dataset_id, data)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
